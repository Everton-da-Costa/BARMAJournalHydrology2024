---
title: "Dynamic Beta Modeling of Seasonal Hydro-environmental Time Series - Test Inferences and Link Function Selection with Temporary Abnormal Regimes"
subtitle: "Application - Itaparica Reservoir"
author: "Everton da Costa"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
bibliography: ../inst/REFERENCES.bib
vignette: >
  %\VignetteIndexEntry{The Useful Volume of the Itaparica Reservoir: A Case Study}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, pdf_output, include=FALSE}
# ---
# title: "Dynamic Beta Modeling of Seasonal Hydro-environmental Time Series"
# subtitle: "Test Inferences and Link Function Selection with Temporary Abnormal Regimes"
# author: "Everton da Costa"
# date: "`r Sys.Date()`"
# output:
#   pdf_document:
#     toc: true
#     toc_depth: 3
#     number_sections: true
#     fig_caption: true
#     keep_tex: true  # Optional: keeps the intermediate LaTeX file
#     highlight: pygments  # Syntax highlighting style
# bibliography: ../inst/REFERENCES.bib
# documentclass: article
# geometry: margin=1in  # Adjust margins
# fontsize: 11pt
# linkcolor: blue  # Hyperlink color
# urlcolor: blue
# ---
```

```{r, html_output, include=FALSE}
# title: "Dynamic Beta Modeling of Seasonal Hydro-environmental Time Series"
# subtitle: "Test Inferences and Link Function Selection with Temporary Abnormal Regimes"
# author: "Everton da Costa"
# date: "`r Sys.Date()`"
# output:
#   rmarkdown::html_vignette:
#     toc: true
#     toc_depth: 3
#     number_sections: true
#     fig_caption: true
# bibliography: ../inst/REFERENCES.bib
# vignette: >
#   %\VignetteIndexEntry{BARMA Models for Hydro-environmental Time Series}
#   %\VignetteEngine{knitr::rmarkdown}
#   %\VignetteEncoding{UTF-8}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 3.5,
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)

library(BARMAJournalHydrology2024)
library(forecast)   # time series
library(ggplot2)    # plotting
library(zoo)        # yearmon handling
library(gridExtra)  # grid.arrange for plots

library(dplyr)
```

# Predicting Reservoir Water Levels - A Machine Learning Solution for Energy Infrastructure

## Executive Summary: 

Solved a critical forecasting problem for Brazil's energy sector, where 
traditional models failed during a historic drought. We used a time series model
$(\beta\text{ARMA})$ that improved forecast accuracy compared
to industry benchmarks like SARIMA and ETS. The model adapts to extreme 
conditions and, unlike standard methods, guarantees operationally valid 
predictions (i.e., never forecasts negative water levels or levels above 100%
capacity). This work, packaged as a reproducible R library, provides a direct 
path to more reliable operational planning, reduced risk of shutdowns, and 
better resource management for critical energy infrastructure.

## Core Competencies Demonstrated

* **Time Series Analysis**: Forecasting, autocorrelation analysis (ACF/PACF), and modeling complex seasonality.

* **Machine Learning**: Application of advanced statistical models ($\beta$ARMA) and comparison against industry benchmarks (SARIMA, ETS).

* **Feature Engineering**: Creating regime-specific indicators (dummy_dry) and interaction terms to build a model that adapts to structural breaks in the data.

* **Model Validation**: Rigorous residual analysis and out-of-sample forecast evaluation using metrics like MAE and RMSE.

* **Scientific Communication**: Translating complex academic research into a practical, reproducible R package and clear documentat

**Key Reference:** 
[Costa, E., Cribari-Neto, F., & Scher, V. T. (2024)](https://doi.org/10.1016/j.jhydrol.2024.131489).
Test inferences and link function selection in dynamic beta modeling of 
seasonal hydro-environmental time series with temporary abnormal regimes. 
*Journal of Hydrology*, 638, 131489.

## Introduction

### The Challenge: Forecasting for Critical Energy Infrastructure

Brazil's energy security relies heavily on its hydroelectric sector, which supplies over 65% of the nation's electricity. Accurate water resource forecasting is therefore essential for economic stability. However, traditional forecasting methods failed during the severe 2012-2020 drought, particularly at the critical Itaparica reservoir.

The core technical challenges were:

* **Bounded Data**: Reservoir levels are proportions, naturally constrained between 0% and 100%. Standard models can yield impossible forecasts outside this range.

* **Seasonality & Regime Changes**: The reservoir's water levels are typically driven by strong seasonal patterns. However, the prolonged 2012-2020 drought created a structural break where this seasonality completely disappeared, rendering traditional forecasting models that rely on consistent seasonal cycles ineffective.

### The Solution: A Regime-Aware $\beta\text{ARMA}$ Model

This project applies a Beta Autoregressive Moving Average ($\beta\text{ARMA}$) model, a framework specifically designed for bounded time series data. The model was tailored to address the operational challenges by:

 * Constraining Forecasts: Naturally keeping all predictions within the realistic 0-100% range.
 
 * Adapting to Regimes: Using feature engineering to detect drought periods and automatically disable seasonal components when they are not present in the data.

 * Optimizing Fit: Systematically testing multiple link functions to ensure the best possible model specification.

### Practical Impact

The resulting $\beta\text{ARMA}$ model delivered consistently more accurate forecasts than industry-standard benchmarks (SARIMA, ETS) across most time horizons. This enhanced predictive power translates directly to significant operational value:

* More reliable planning for energy generation.
* Reduced risk of emergency shutdowns.
* Better-informed water resource management during droughts.

## Data Analysis and Key Insights

```{r, config_data_visualization, include=FALSE}
# Series size and end time
sample_size <- length(itaparica_ts)
end_time_series <- time(itaparica_ts)[sample_size] + 1

# Size font of the plot
ggplot_size_font <- 9

# ggplot theme
ggplot_theme <- theme(
  legend.position = "bottom",
  title = element_text(size = ggplot_size_font),
  axis.text = element_text(size = ggplot_size_font),
  axis.title = element_text(size = ggplot_size_font),
  legend.text = element_text(size = ggplot_size_font),
  legend.title = element_text(size = ggplot_size_font)
  )

# ggplot theme forecast plot
ggplot_theme_forecast <- theme(
  legend.position = "right",
  title = element_text(size = ggplot_size_font),
  axis.text = element_text(size = ggplot_size_font),
  axis.title = element_text(size = ggplot_size_font),
  legend.text = element_text(size = ggplot_size_font),
  legend.title = element_text(size = ggplot_size_font)
)

# y-axis scale
ggplot_scale_y <-
  scale_y_continuous(
    breaks = seq(0.1, 1.00, 0.10),
    limits = c(0.1, 1.0)
  )

# x-axis scale
ggplot_scale_x <- scale_x_continuous(
  breaks = seq(1999, end_time_series, 2),
  limits = c(1999, end_time_series)
)
```

### Dataset Overview

**Data Source:** Itaparica Reservoir operational data (1999-2024)  
**Key Metric:** Useful volume as percentage of total capacity (0-100%)  
**Context:** Critical input for energy generation planning and grid stability

The dataset spans 25 years of monthly observations, providing sufficient historical depth to capture both normal operational cycles and extreme events like the 2012-2020 drought.

```{r, ggplot_itaparica, include=FALSE}
# -------------------------------------------------------------------------- #
# Time series plot
# -------------------------------------------------------------------------- #
ggplot_itaparica <- ggplot(itaparica_df, aes(time, y)) +
  geom_point(size = 0.5) +
  geom_line(aes(group = 1)) +
  ggplot_scale_x +
  ggplot_scale_y +
  ggplot_theme +
  guides(colour = guide_legend(title = "Temporary regimes"))

# -------------------------------------------------------------------------- #
# Autocorrelation function (ACF) plot
# -------------------------------------------------------------------------- #
ggacf_plot <- ggAcf(itaparica_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("ACF")

# -------------------------------------------------------------------------- #
# Partial autocorrelation function (PACF) plot
# -------------------------------------------------------------------------- #
ggpacf_plot <- ggPacf(itaparica_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("PACF")
```

```{r, print_ggplot_itaparica, message=FALSE, echo=FALSE, fig.height=5, fig.cap="Useful volume of the Itaparica reservoir (top), with its corresponding autocorrelation function (bottom left) and partial autocorrelation function (bottom right)."}
# -------------------------------------------------------------------------- #
# Grid all plots
# -------------------------------------------------------------------------- #
grid.arrange(
  ggplot_itaparica,
  ggacf_plot,
  ggpacf_plot,
  layout_matrix = rbind(c(1, 1), c(2, 3))
)
```

### Uncovering Key Patterns: EDA Insights

#### 1. Operational Regime Change
The data reveals a fundamental shift in operational patterns during 2012-2020. Normal seasonal variations completely disappeared during this drought period, creating a **structural break** that traditional forecasting methods cannot handle. This explains why existing models failed during the crisis. This insight was critical: any successful model must be able to account for this regime change. This directly informed the feature engineering strategy.

```{r, descriptive, include=FALSE}
# -------------------------------------------------------------------------- #
# Descriptive statistics: Useful volume of the Itaparica reservoir
# -------------------------------------------------------------------------- #
descriptive_df <- data.frame(
  min             = min(itaparica_ts),
  max             = max(itaparica_ts),
  median          = median(itaparica_ts),
  mean            = mean(itaparica_ts),
  sd              = sd(itaparica_ts),
  skewness        = moments::skewness(itaparica_ts),
  excess_kurtosis = moments::kurtosis(itaparica_ts)
)

# Round to two decimals
descriptive_df <- round(descriptive_df, 2)
```

```{r, print_descriptive, echo=FALSE}
knitr::kable(
  descriptive_df,
  caption = 
    "Descriptive statistics of the Itaparica reservoir's useful volume."
)
```

One observation slightly exceeded the reservoir's highest safety value: 1.007 in June 2002. As noted, this occurs rarely and places the system outside its safe operating window. Since this was a one-off event and not relevant to the dynamics of the series, this value was replaced by 0.9999.

**Key Findings:**

 - **High Volatility:** Standard deviation of 29% indicates significant operational. uncertainty
 
 - **Extreme Values:** Minimum of 10% capacity represents critical operational threshold.
 
 - **Distribution:** Slight positive skew suggests more frequent low-volume periods.

#### 2. Drought Impact Analysis

```{r, ggplot_abnormal_period, include=FALSE}
# -------------------------------------------------------------------------- #
# Create data frame with abnormal period dummy
# -------------------------------------------------------------------------- #
time_vector <- seq(
  time(itaparica_ts)[1],
  time(itaparica_ts)[sample_size],
  1 / 12
)
time_vector_yearmon <- as.yearmon(time_vector)

itaparica_ggplot_df <- data.frame(
  time = time_vector_yearmon,
  y = itaparica_ts
)

end_train_date <- as.yearmon("2024-06")

# Abnormal period definition
start_dap <- as.yearmon("2012-10")
end_dap <- as.yearmon("2020-05")
dap_time <- (itaparica_ggplot_df$time >= start_dap &
  itaparica_ggplot_df$time <= end_dap)

dap <- as.numeric(dap_time)

# Labeling regimes
itaparica_ggplot_df$dap <- dap
itaparica_ggplot_df$colour1 <- ifelse(itaparica_ggplot_df$dap == 0,
  "Normal", "Abnormal"
)

# Plot abnormal periods
ggplot_abnormal_period <- ggplot(
  itaparica_ggplot_df,
  aes(time, y, colour = colour1)
) +
  geom_point(size = 0.5) +
  geom_line(aes(group = 1)) +
  ggplot_scale_x +
  ggplot_scale_y +
  ggplot_theme +
  guides(colour = guide_legend(title = "Temporary regimes"))
```

```{r, print_ggplot_abnormal_period, echo=FALSE, fig.cap = "Visualization of the Itaparica reservoir's useful volume, highlighting the abnormal drought regime between October 2012 and May 2020."}
print(ggplot_abnormal_period)
```

The 8-year drought created an **abnormal operational regime** where:

- Normal seasonal patterns vanished

- Volume remained consistently below 40% capacity

- Traditional seasonal forecasting became unreliable

**Practical Implication:** Any forecasting system must detect and adapt to such regime changes automatically.

#### 3. Seasonal Pattern Analysis

```{r, ggmonthplot, include=FALSE}
# Monthly seasonality plot
ggmonthplot_itaparica_ts <- ggmonthplot(itaparica_ts) +
  labs(title = " ", x = "Month", y = " ") + 
  ggplot_scale_y +
  ggplot_theme
```

```{r, print_ggmonthplot, echo=FALSE, fig.cap = "Monthly plot illustrating the seasonal pattern of the Itaparica reservoir's useful volume across different years."}
print(ggmonthplot_itaparica_ts)
```

```{r, ggseasonplot, include=FALSE}
# Seasonality plot by year
ggseasonplot_itaparica_ts <- ggseasonplot(itaparica_ts) +
  labs(title = " ", x = "Month", y = " ") + 
  ggplot_scale_y +
  ggplot_theme + 
  theme(legend.position = "right")
```

```{r, print_ggseasonplot, echo=FALSE, fig.cap = "Seasonal plot comparing the useful volume patterns across different years, emphasizing variations during and outside the drought period."}
print(ggseasonplot_itaparica_ts)
```

**Operational Insights:**

- **Peak Season:** June-July (wet season) - volumes typically reach 60-80%

- **Low Season:** October-December (dry season) - volumes drop to 40-50%

- **Critical Period:** January-March - steepest decline requiring careful management

This seasonality drives energy generation planning and maintenance scheduling throughout the year.

### Strategic Feature Engineering

Based on these insights, we developed several key predictors for the model:

**Regime Detection:**
- Drought Regime Indicator (`dummy_dry`):  Structural break between 2012-2020 where reservoir levels behaved abnormally. This binary feature was created to explicitly signal this 'drought regime' to the model.

**Seasonal Modeling:**
- Harmonic Regressor (`hs`, `hc`): Strong Sassonality in annual cycles was 
present was captured by Sine/cosine terms 

- `regime_interactions`: Seasonal effects that activate only during normal periods
- `monthly_dummies`: Specific adjustments for March and October transitions

**Modeling Strategy:** The model automatically "turns off" seasonal patterns during detected drought periods, preventing inappropriate seasonal forecasts when historical patterns break down.

### Data Quality and Validation

- **Completeness:** No missing values in the 25-year series
- **Consistency:** Values properly bounded between 0-1 as expected
- **Modeling Strategy:** Patterns align with known operational and climatic factors
- **Regime Detection:** Clear breakpoints correspond to documented drought periods

This dataset provides an ideal foundation for developing and validating advanced forecasting models that can handle both normal operations and crisis conditions.

## Model Fitting: $\beta$ARMA

Now that we understand the data's structure, we can proceed with modeling. Our
goal is to accurately forecast the reservoir's useful volume. We will fit our
proposed $\beta$ARMA model, which is specifically designed for bounded time 
series. To evaluate its effectiveness, we will benchmark its performance
against standard time series models like SARIMA, SARIMAX, and ETS.

### Train-Test Split

To evaluate model performance on unseen data, we split the series
chronologically. This simulates a real-world forecasting scenario. The model
will be trained on data up to January 2023, and its forecasting accuracy will
be tested on the subsequent 12 months (February 2023 to January 2024).
[Costa, E., Cribari-Neto, F., & Scher, V. T. (2024)](https://doi.org/10.1016/j.jhydrol.2024.131489).

```{r, split_data, include=FALSE}
stop_train_date <- as.yearmon("2023-01")

y_train_loc <- itaparica_df$time <= stop_train_date
y_test_loc <- itaparica_df$time > stop_train_date

y_train_df <- itaparica_df[y_train_loc, ]
y_test_df <- itaparica_df[y_test_loc, ]

y_train_ts <- ts(y_train_df$y, end = stop_train_date, frequency = 12)
y_test_ts <- ts(y_test_df$y, start = stop_train_date + 1 / 12, frequency = 12)
```

### Regressor Construction

Based on our visual analysis, we construct several regressors to capture the
series' key features. This feature engineering step is critical for building a
model.

* Drought Dummy (dummy_dry): A binary indicator that equals 1 from October 2012
to May 2020. This allows the model to explicitly account for the different
behavior during the abnormal drought regime.

* Harmonic Features (`hs`, `hc`): A pair of sine (`sin`) and cosine (`cos`)
terms to model the primary annual seasonality. These smooth, cyclical features
are effective at capturing the main seasonal pattern.

* Interaction for Regime-Dependent Seasonality: A key finding from our analysis
was that the typical seasonal pattern vanished during the prolonged drought. 
To model this, we interact the seasonal features with a "non-drought" indicator
`(1 - dummy_dry)`. This technique effectively "turns off" the seasonality
during the drought period, leading to more accurate modeling.

This results in the following regressors used in the model:

* `hs1dummy_dry`: The sine-wave seasonal effect, applied only outside the
drought.
* `hc1dummy_dry`: The cosine-wave seasonal effect, applied only outside the
drought.
* `d03_1dummy_dry` and `d10_1dummy_dry`: Specific dummy variables for March and
October, also applied only outside the drought, to capture sharp monthly
effects not fully explained by the smooth harmonic terms.

```{r, regressor_construction, include=FALSE}
len_y_train <- length(y_train_ts)
len_y_test <- length(y_test_ts)

vec_train <- 1:len_y_train
vec_test <- (max(vec_train) + 1):(max(vec_train) + len_y_test)

# Dummy variable for the dry period
start_dry_period <- as.yearmon("2012-10")
end_dry_period <- as.yearmon("2020-05")

dry_period_time <- (itaparica_df$time >= start_dry_period &
  itaparica_df$time <= end_dry_period)

dummy_dry <- as.numeric(dry_period_time)
dummy_dry_train <- dummy_dry[vec_train]
dummy_dry_test <- dummy_dry[vec_test]
y_train_df$dummy_dry <- dummy_dry_train

# Harmonic terms and interactions
hs_train <- sin(2 * pi * vec_train / 12)
hc_train <- cos(2 * pi * vec_train / 12)
hs1dummy_dry_train <- hs_train * (1 - dummy_dry_train)
hc1dummy_dry_train <- hc_train * (1 - dummy_dry_train)

hs_test <- sin(2 * pi * vec_test / 12)
hc_test <- cos(2 * pi * vec_test / 12)
hs1dummy_dry_test <- hs_test * (1 - dummy_dry_test)
hc1dummy_dry_test <- hc_test * (1 - dummy_dry_test)

# Monthly dummy variables and interactions
d03_train <- as.numeric(ifelse(cycle(y_train_ts) == 3, 1, 0))
d10_train <- as.numeric(ifelse(cycle(y_train_ts) == 10, 1, 0))
d03_1dummy_dry_train <- d03_train * (1 - dummy_dry_train)
d10_1dummy_dry_train <- d10_train * (1 - dummy_dry_train)

d03_test <- as.numeric(ifelse(cycle(y_test_ts) == 3, 1, 0))
d10_test <- as.numeric(ifelse(cycle(y_test_ts) == 10, 1, 0))
d03_1dummy_dry_test <- d03_test * (1 - dummy_dry_test)
d10_1dummy_dry_test <- d10_test * (1 - dummy_dry_test)

# Regressor matrices
X_train <- cbind(
  hs1dummy_dry = hs1dummy_dry_train,
  hc1dummy_dry = hc1dummy_dry_train,
  dummy_dry = dummy_dry_train,
  d03_1dummy_dry = d03_1dummy_dry_train,
  d10_1dummy_dry = d10_1dummy_dry_train
)

X_test <- cbind(
  hs1dummy_dry_hat = hs1dummy_dry_test,
  hc1dummy_dry_hat = hc1dummy_dry_test,
  dummy_dry_hat = dummy_dry_test,
  d03_1dummy_dry_hat = d03_1dummy_dry_test,
  d10_1dummy_dry_hat = d10_1dummy_dry_test
)
```

Comparing Models
In this section, we compare the performance of different time series models.
Our primary focus is the $\beta$ARMA model, which explicitly handles the
bounded nature of the reservoir data. We include SARIMA, SARIMAX, and ETS as
widely-used benchmarks to demonstrate the relative advantage of our specialized
approach.

### $\beta$ARMA model with different link functions

The $\beta$ARMA model is our primary tool. A key component is the link
function, which maps the model's linear predictors to the (0, 1) scale of the
reservoir volume. The choice of link function can impact model fit, especially
how it handles values near the boundaries (0 and 1). We will fit the model
using three common link functions - `logit`, `log-log`, and `cloglog` - to
determine which provides the best fit for our data.

#### Logit

The model's dynamic structure (AR and MA orders) was selected based on a
careful analysis of the series' autocorrelation and partial autocorrelation
functions. The final specification was chosen to capture both short-term
persistence (AR terms 1 and 3) and complex, long-range seasonal dependencies
(MA terms 12, 19, and 24) identified in the residual diagnostics.

```{r}
# BARMA model to be estimate using different link functions
ar_vec <- c(1, 3)
ma_vec <- c(12, 19, 24)
```

```{r, fit_BARMA_logit}
# logit
fit_BARMA_logit <- barma(
  y_train_ts,
  ar = ar_vec,
  ma = ma_vec,
  link = "logit",
  X = X_train,
  X_hat = X_test
)
knitr::kable(
  fit_BARMA_logit$model,
  caption = "Estimated coefficients for the $\\beta ARMA$ model with logit link function."
)
```

#### Loglog
```{r, fit_BARMA_loglog}
# loglog
fit_BARMA_loglog <- barma(
  y_train_ts,
  ar = ar_vec,
  ma = ma_vec,
  link = "loglog",
  X = X_train,
  X_hat = X_test
)

knitr::kable(
  fit_BARMA_loglog$model,
  caption = "Estimated coefficients for the $\\beta ARMA$ model with loglog link function."
)
```

#### Cloglog
```{r, fit_BARMA_cloglog}
# cloglog
fit_BARMA_cloglog <- barma(
  y_train_ts,
  ar = ar_vec,
  ma = ma_vec,
  link = "cloglog",
  X = X_train,
  X_hat = X_test
)
knitr::kable(
  fit_BARMA_cloglog$model,
  caption = "Estimated coefficients for the $\\beta ARMA$ model with cloglog link function."
)
```

### Residual analysis with different link functions

A crucial step in model validation is to analyze the model's residuals. As
noted in the original study, a well-specified model should capture all
systematic patterns in the data, leaving residuals that are essentially random
noise with no serial correlation.

We can visually inspect this by plotting the Autocorrelation Function (ACF) of
the residuals for each model. In the plots below, we are looking for
significant spikes that extend beyond the dashed blue confidence bands. The
presence of such spikes would indicate that the model has failed to capture all
of the underlying dynamics of the series.

The results will show that the `logit` and `loglog` link functions produce
well-behaved residuals, validating their model specification. In contrast, the
`cloglog` model will show significant residual autocorrelation, suggesting it
is not an appropriate choice for this time series.

```{r, ggplot_residuals, include=FALSE}
# Extract residuals
residual_BARMA_logit <- fit_BARMA_logit$resid2
residual_BARMA_loglog <- fit_BARMA_loglog$resid2
residual_BARMA_cloglog <- fit_BARMA_cloglog$resid2

# Plot ACF of residuals
ggacf_resid_logit <- ggAcf(residual_BARMA_logit) +
  labs(title = "ACF of BARMA residuals (logit link)", x = "Lag", y = "ACF") + 
  ggplot_theme

ggacf_resid_loglog <- ggAcf(residual_BARMA_loglog) +
  labs(title = "ACF of BARMA residuals (loglog link)", x = "Lag", y = "ACF") + 
  ggplot_theme

ggacf_resid_cloglog <- ggAcf(residual_BARMA_cloglog) +
  labs(title = "ACF of BARMA residuals (cloglog link)", x = "Lag", y = "ACF") + 
  ggplot_theme

```

```{r, print_ggplot_residuals, fig.height=10, echo=FALSE}
# Arrange plots vertically
grid.arrange(
  ggacf_resid_logit,
  ggacf_resid_loglog,
  ggacf_resid_cloglog,
  ncol = 1
)
```

### Forecast visualization with different link functions

The ultimate test of a time series model is its forecasting accuracy on unseen
data. This plot compares the 12-month forecasts from each link function against
the actual observed values for the Itaparica reservoir.

As anticipated from the residual analysis, the forecasts from the `logit` and
`loglog` models track the observed data much more closely. The `cloglog`
model's predictions are visibly less accurate, confirming that the choice of
link function has a direct and practical impact on model performance.

```{r, ggplot_forecastd_link, include=FALSE}
# Prepare data
n <- length(y_test_ts)
dates <- as.Date(as.yearmon(time(y_test_ts)))
months <- format(dates, "%b")

# Capitalize the first letter of each month
months <- toupper(substr(months, 1, 1)) %>% paste0(substr(months, 2, 3))
months <- tools::toTitleCase(months)

forecasts_df <- data.frame(
  y_test_ts = y_test_ts[1:n],
  logit = fit_BARMA_logit$forecast[1:n],
  loglog = fit_BARMA_loglog$forecast[1:n],
  cloglog = fit_BARMA_cloglog$forecast[1:n],
  month = factor(months)
) %>%
  mutate(time = 1:n)

# Create visualization
ggplot_forecastd_link <- ggplot(forecasts_df, aes(x = time)) +

  # Data points and lines
  geom_line(aes(y = logit, colour = "Logit"), linewidth = 0.8) +
  geom_line(aes(y = loglog, colour = "Log-log"), linewidth = 0.8) +
  geom_line(aes(y = cloglog, colour = "Clog-log"), linewidth = 0.8) +
  geom_point(aes(y = y_test_ts, shape = "Observed data"),
    color = "#00BFC4", size = 3
  ) +

  # Customize aesthetics
  scale_colour_manual(
    name = "Link Functions",
    breaks = c("Logit", "Log-log", "Clog-log"),
    values = c(
      "Logit" = "#F8766D",
      "Log-log" = "#C77CFF",
      "Clog-log" = "#7CAE00"
    )
  ) +
  scale_shape_manual(
    name = "Actual Values",
    values = c("Observed data" = 16)
  ) +

  # Labels and scales
  labs(
    x = "Time (Months)",
    y = "Predicted Values",
  ) +
  scale_x_continuous(
    breaks = seq(1, n, 1),
    limits = c(1, n),
    labels = forecasts_df$month
  ) +
  scale_y_continuous(
    breaks = seq(0.3, 1.0, 0.1),
    limits = c(0.3, 1.0),
    labels = scales::number_format(accuracy = 0.1)
  ) +
  ggplot_theme_forecast
```

```{r, print_ggplot_forecastd_link, fit.heigh=7, echo=FALSE, fig.cap = "Comparative forecast visualization of different link functions (logit, log-log, clog-log) for the $\\beta ARMA$ model."}
print(ggplot_forecastd_link)
```

### Selecting the Final $\beta$ARMA Model

Based on the analysis, the $\beta$ARMA model with the `log-log` link function
is selected as our final candidate for forecasting. This decision is supported
by evidence from the source article:

* Information Criteria: The log-log model yielded the most favorable (lowest)
values for AIC, BIC, and HQIC, suggesting a better trade-off between model fit
and complexity.

* Residual Analysis: Crucially, portmanteau tests confirmed that the `log-log`
model's residuals have no significant serial correlation, a key indicator of a
well-specified model. The `cloglog` model failed this test, making it an
unreliable choice.

With a validated and selected model, we can now benchmark its performance
against other standard time series forecasting methods.

## Model Fitting: Traditional Benchmarks

To properly evaluate the performance of the $\beta$ARMA model, we
benchmark it against widely-used, traditional time series models.

For the benchmark models (SARIMA, SARIMAX, and ETS), we have explicitly defined
their structures (e.g., `order = c(1, 0, 0)`). While automatic selection
functions like `forecast::auto.arima()` are powerful tools for exploratory
analysis, specifying the model orders directly serves a critical purpose here:
**reproducibility**. This approach guarantees that the results in this vignette
will remain identical to those from our original analysis, regardless of future
updates to the `forecast` package or its selection algorithms. This ensures a
stable and fair comparison against our proposed $\beta$ARMA model.

### SARIMA

```{r}
fit_SARIMA <- forecast::Arima(
  y = y_train_ts,
  order = c(1, 0, 0),
  seasonal = c(1, 0, 1)
)
```

### SARIMAX

```{r}
fit_SARIMAX <- forecast::Arima(
  y = y_train_ts,
  order = c(2, 0, 2),
  seasonal = c(2, 0, 1),
  xreg = cbind(
    dummy_dry = dummy_dry_train,
    d03_1dummy_dry = d03_1dummy_dry_train,
    d10_1dummy_dry = d10_1dummy_dry_train
  )
)
```

### ETS

```{r}
fit_ETS <- forecast::ets(y_train_ts, model = "ANA")
```

## Comparison models

Having fitted both our proposed $\beta$ARMA model and the traditional
benchmarks, we now arrive at the crucial evaluation stage. The primary goal is
to determine which model provides the most accurate out-of-sample forecasts, a
key objective from our published research.

Following the methodology from our paper 
[Costa, E., Cribari-Neto, F., & Scher, V. T. (2024)](https://doi.org/10.1016/j.jhydrol.2024.131489), this comparison is
performed on the held-out test set, which covers the 12-month period from
February 2023 to January 2024. We will assess performance using two
complementary approaches:

1 - Quantitative Metrics: Calculating the Mean Absolute Error (MAE) and Root
Mean Squared Error (RMSE) to numerically score forecast accuracy over the
forecast horizon.

2 - Visual Comparison: Plotting the forecasts from all models against the
observed data to visually inspect how well they track the series' real-world
behavior.


```{r, forecast_models, include=FALSE}
forecast_BARMA <- fit_BARMA_loglog$forecast
forecast_SARIMA <- forecast(fit_SARIMA, h = len_y_test)$mean
forecast_SARIMAX <- forecast(
  fit_SARIMAX,
  xreg = cbind(
    dummy_dry = dummy_dry_test,
    d03_1dummy_dry = d03_1dummy_dry_test,
    d10_1dummy_dry = d10_1dummy_dry_test
  ),
  h = len_y_test
)$mean
forecast_ETS <- forecast(fit_ETS, h = len_y_test)$mean
```

### Evaluation Metrics

The evaluation metrics below confirm the $\beta$ARMA model's superior performance. Across nearly all forecast horizons, it delivered lower Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) compared to the benchmark models.

```{r, eval_metrics, include=FALSE}
evaluation_metrics <- function(actual_values, forecasts) {
  mae <- mean(abs(forecasts - actual_values))
  rmse <- sqrt(mean((forecasts - actual_values)^2))
  data.frame(MAE = mae, RMSE = rmse)
}

MAE_BARMA <- RMSE_BARMA <- matrix(nrow = 1, ncol = len_y_test)
MAE_SARIMA <- RMSE_SARIMA <- matrix(nrow = 1, ncol = len_y_test)
MAE_SARIMAX <- RMSE_SARIMAX <- matrix(nrow = 1, ncol = len_y_test)
MAE_ETS <- RMSE_ETS <- matrix(nrow = 1, ncol = len_y_test)

for (i in 1:len_y_test) {
  actual_values <- y_test_ts[1:i]
  metrics_BARMA <- evaluation_metrics(actual_values, forecast_BARMA[1:i])
  metrics_SARIMA <- evaluation_metrics(actual_values, forecast_SARIMA[1:i])
  metrics_SARIMAX <- evaluation_metrics(actual_values, forecast_SARIMAX[1:i])
  metrics_ETS <- evaluation_metrics(actual_values, forecast_ETS[1:i])

  MAE_BARMA[i] <- metrics_BARMA$MAE
  RMSE_BARMA[i] <- metrics_BARMA$RMSE
  MAE_SARIMA[i] <- metrics_SARIMA$MAE
  RMSE_SARIMA[i] <- metrics_SARIMA$RMSE
  MAE_SARIMAX[i] <- metrics_SARIMAX$MAE
  RMSE_SARIMAX[i] <- metrics_SARIMAX$RMSE
  MAE_ETS[i] <- metrics_ETS$MAE
  RMSE_ETS[i] <- metrics_ETS$RMSE
}

MAE_results <- rbind(MAE_BARMA, MAE_SARIMA, MAE_SARIMAX, MAE_ETS)
RMSE_results <- rbind(RMSE_BARMA, RMSE_SARIMA, RMSE_SARIMAX, RMSE_ETS)

MAE_results <- round(MAE_results * 100, 2)
RMSE_results <- round(RMSE_results * 100, 2)

rownames(MAE_results) <- c("MAE_BARMA", "MAE_SARIMA", "MAE_SARIMAX", "MAE_ETS")
rownames(RMSE_results) <- c("RMSE_BARMA", "RMSE_SARIMA", "RMSE_SARIMAX", "RMSE_ETS")

colnames(MAE_results) <- colnames(RMSE_results) <- 1:12
```

```{r, print_eval_metrics1, echo=FALSE}
knitr::kable(
  MAE_results,
  caption = 
    "MAEs ($\\times 100$) of $\\beta ARMA$ (loglog), 
  SARIMA, SARIMAX and ETS forecasts, Itaparica reservoir useful volume."
)
```

```{r, print_eval_metrics2, echo=FALSE}
knitr::kable(
  RMSE_results,
  caption = 
    "RMSEs ($\\times 100$) of $\\beta ARMA$ (loglog), 
  SARIMA, SARIMAX and ETS forecasts, Itaparica reservoir useful volume."
)
```

The results clearly show the superior performance of the $\beta$ARMA model.
According to both MAE and RMSE, it provided the most accurate forecasts for
nearly every forecast horizon. A notable feature of the $\beta$ARMA model is
that it will never produce improper forecasts (i.e., values outside the
interval), a risk inherent in the other models.

### Forecast Comparison Plot

A visual comparison of the forecasts provides further insight. The plot below
shows the actual observed values from the test set (blue dots) against the
forecasts from the four models.


```{r, ggplot_forecast_comparison, include=FALSE}
# Prepare data
n <- length(y_test_ts)
dates <- as.Date(as.yearmon(time(y_test_ts)))
months <- format(dates, "%b")

# Capitalize the first letter of each month
months <- toupper(substr(months, 1, 1)) %>% paste0(substr(months, 2, 3))
months <- tools::toTitleCase(months)

# Create data frame with forecasts
forecasts_df <- data.frame(
  y_test_ts = y_test_ts[1:n],
  BARMA = fit_BARMA_loglog$forecast[1:n],
  SARIMA = forecast(fit_SARIMA)$mean[1:n],
  SARIMAX = forecast_SARIMAX[1:n],
  ETS = forecast(fit_ETS)$mean[1:n],
  month = factor(months)
) %>%
  mutate(time = 1:n)

# Create visualization
ggplot_forecast_comparison <- ggplot(forecasts_df, aes(x = time)) +

  # Data points and lines
  geom_line(aes(y = BARMA, colour = "BARMA"), linewidth = 0.8) +
  geom_line(aes(y = SARIMA, colour = "SARIMA"), linewidth = 0.8) +
  geom_line(aes(y = SARIMAX, colour = "SARIMAX"), linewidth = 0.8) +
  geom_line(aes(y = ETS, colour = "ETS"), linewidth = 0.8) +
  geom_point(aes(y = y_test_ts, shape = "Observed data"),
    color = "#00BFC4", size = 2
  ) +

  # Customize aesthetics
  scale_colour_manual(
    name = "Models",
    breaks = c("BARMA", "SARIMA", "SARIMAX", "ETS"),
    values = c(
      "BARMA" = "#C77CFF",
      "SARIMA" = "#56B4E9",
      "SARIMAX" = "#009E73",
      "ETS" = "#7CAE00"
    )
  ) +
  scale_shape_manual(
    name = "Actual Values",
    values = c("Observed data" = 16)
  ) +

  # Labels and scales
  labs(
    x = "Time (Months)",
    y = "Predicted Values"
  ) +
  scale_x_continuous(
    breaks = seq(1, n, 1),
    limits = c(1, n),
    labels = forecasts_df$month
  ) +
  scale_y_continuous(
    breaks = seq(0.3, 1.0, 0.1),
    limits = c(0.3, 1.0),
    labels = scales::number_format(accuracy = 0.1)
  )
```

```{r, print_ggplot_forecast_comparison, fit.heigh=7, echo=FALSE, fig.cap = "Comparative forecast performance of $\\beta ARMA$, SARIMA, SARIMAX, and ETS models against observed reservoir useful volume."}
print(ggplot_forecast_comparison)
```

Visually, the forecast from the $\beta$ARMA model is the only one that
effectively tracks the evolution of the data over the 12-month horizon. It
successfully captures the general trend and turning points of the reservoir's
useful volume, confirming the quantitative results from the evaluation metrics.

## Conclusion and Future Work

The analysis demonstrates that the $\beta$ARMA model, which accounts for the bounded nature of reservoir data and adapts to operational regime changes, is a significantly more accurate and reliable forecasting tool than traditional models for this application.

**Key Takeaways**:

* Superior Accuracy: The $\beta$ARMA model consistently outperformed SARIMA, SARIMAX, and ETS in out-of-sample forecasting.

* Operational Reliability: Unlike standard models, the $\beta$ARMA model guarantees that forecasts will remain within the valid 0%-100% range, preventing nonsensical predictions. 

* Adaptability: Strategic feature engineering allowed the model to automatically handle the structural break caused by the drought, a key failure point for simpler models. 

**Potential Next Steps**:

* Model Deployment: Packaging this model into a production-ready API for real-time forecasting.

* Hyperparameter Tuning: Exploring automated tuning methods to further optimize the model's AR and MA components.

* Alternative Models: Benchmarking against other non-linear time series models, such as LSTMs or Prophet, to see if further accuracy gains are possible.
